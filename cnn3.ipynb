{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8991d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atul1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting validation data...\n",
      "Error processing .\\data\\Beethoven\\Anhang 14-3.mid: Could not decode key with 3 flats and mode 255\n",
      "Extracting test data...\n",
      "Error processing .\\data\\Mozart\\K281 Piano Sonata n03 3mov.mid: Could not decode key with 2 flats and mode 2\n",
      "Epoch 1/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.3167 - loss: 2.5605 - val_accuracy: 0.5644 - val_loss: 1.0759 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.5591 - loss: 1.2815 - val_accuracy: 0.6380 - val_loss: 0.9917 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.6084 - loss: 1.1998 - val_accuracy: 0.6933 - val_loss: 0.8412 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.6603 - loss: 1.1045 - val_accuracy: 0.7117 - val_loss: 0.9162 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.6833 - loss: 0.9558 - val_accuracy: 0.7546 - val_loss: 0.7460 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.7374 - loss: 0.7991 - val_accuracy: 0.7669 - val_loss: 0.6070 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.7582 - loss: 0.7056 - val_accuracy: 0.7914 - val_loss: 0.5305 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.8283 - loss: 0.5807 - val_accuracy: 0.7791 - val_loss: 0.5956 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.8528 - loss: 0.4517 - val_accuracy: 0.7669 - val_loss: 0.5669 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - accuracy: 0.8861 - loss: 0.3278 - val_accuracy: 0.7975 - val_loss: 0.5366 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - accuracy: 0.9085 - loss: 0.2560 - val_accuracy: 0.7791 - val_loss: 0.5666 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - accuracy: 0.9259 - loss: 0.2786 - val_accuracy: 0.8282 - val_loss: 0.5531 - learning_rate: 5.0000e-04\n",
      "✅ Final Test Accuracy: 80.43%\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# Imports and Configuration\n",
    "# ----------------------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Constants\n",
    "DATA_DIR = os.path.join('.', 'data')\n",
    "COMPOSERS = ['Bach', 'Beethoven', 'Chopin', 'Mozart']\n",
    "SUPPORTED_EXT = ('.mid', '.midi')\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 1: MIDI File Collection\n",
    "# ----------------------------------------\n",
    "def get_midi_files(data_dir, composers):\n",
    "    all_paths = []\n",
    "    for composer in composers:\n",
    "        folder = os.path.join(data_dir, composer)\n",
    "        files = [os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith(SUPPORTED_EXT)]\n",
    "        for file in files:\n",
    "            all_paths.append((file, composer))\n",
    "    return pd.DataFrame(all_paths, columns=['filepath', 'composer'])\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 2: MIDI Statistics Extraction\n",
    "# ----------------------------------------\n",
    "def extract_note_statistics(file_path):\n",
    "    midi_data = pretty_midi.PrettyMIDI(file_path)\n",
    "    pitches = [note.pitch for instr in midi_data.instruments for note in instr.notes]\n",
    "    velocities = [note.velocity for instr in midi_data.instruments for note in instr.notes]\n",
    "    _, tempos = midi_data.get_tempo_changes()\n",
    "\n",
    "    return {\n",
    "        'pitch_std': np.std(pitches),\n",
    "        'pitch_min': np.min(pitches),\n",
    "        'pitch_max': np.max(pitches),\n",
    "        'velocity_mean': np.mean(velocities),\n",
    "        'velocity_std': np.std(velocities),\n",
    "        'velocity_min': np.min(velocities),\n",
    "        'velocity_max': np.max(velocities),\n",
    "        'tempo_mean': np.mean(tempos),\n",
    "        'tempo_min': np.min(tempos),\n",
    "        'tempo_max': np.max(tempos),\n",
    "    }\n",
    "\n",
    "def extract_statistics_dataframe(df):\n",
    "    stats = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            feats = extract_note_statistics(row['filepath'])\n",
    "            feats['composer'] = row['composer']\n",
    "            stats.append(feats)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in stats for {row['filepath']}: {e}\")\n",
    "    return pd.DataFrame(stats)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 3: Multichannel Piano Roll\n",
    "# ----------------------------------------\n",
    "def process_multichannel_midi(file_path, fs=8, max_length=150):\n",
    "    midi = pretty_midi.PrettyMIDI(file_path)\n",
    "    piano_roll = midi.get_piano_roll(fs=fs)\n",
    "    binary_roll = (piano_roll > 0).astype(np.float32)\n",
    "    velocity_roll = (piano_roll / 127.0).astype(np.float32)\n",
    "\n",
    "    instrument_rolls = [instr.get_piano_roll(fs=fs) for instr in midi.instruments]\n",
    "    max_len = max((r.shape[1] for r in instrument_rolls), default=0)\n",
    "    inst_combined = np.zeros((128, max_len))\n",
    "    for roll in instrument_rolls:\n",
    "        roll = np.pad(roll, ((0, 0), (0, max_len - roll.shape[1])), mode='constant')\n",
    "        inst_combined += (roll > 0).astype(np.float32)\n",
    "    inst_combined = (inst_combined / inst_combined.max()).astype(np.float32) if inst_combined.max() > 0 else inst_combined\n",
    "\n",
    "    expressive_roll = np.zeros((128, max_len))\n",
    "    for instr in midi.instruments:\n",
    "        for note in instr.notes:\n",
    "            start = int(note.start * fs)\n",
    "            end = int(note.end * fs)\n",
    "            expressive_roll[note.pitch, start:end] = 1\n",
    "    expressive_roll = expressive_roll.astype(np.float32)\n",
    "\n",
    "    def fix_length(arr): return np.pad(arr, ((0, 0), (0, max(0, max_length - arr.shape[1]))), mode='constant')[:, :max_length]\n",
    "    binary_roll = fix_length(binary_roll)\n",
    "    velocity_roll = fix_length(velocity_roll)\n",
    "    inst_combined = fix_length(inst_combined)\n",
    "    expressive_roll = fix_length(expressive_roll)\n",
    "\n",
    "    return np.stack([binary_roll, velocity_roll, inst_combined, expressive_roll], axis=-1)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 4: Dataset Creation\n",
    "# ----------------------------------------\n",
    "def create_combined_dataset(df, fs=8, max_length=150):\n",
    "    X_roll, X_stats, y = [], [], []\n",
    "    label_map = {name: idx for idx, name in enumerate(COMPOSERS)}\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            roll = process_multichannel_midi(row['filepath'], fs=fs, max_length=max_length)\n",
    "            stats = extract_note_statistics(row['filepath'])\n",
    "            X_roll.append(roll)\n",
    "            X_stats.append(list(stats.values()))\n",
    "            y.append(label_map[row['composer']])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {row['filepath']}: {e}\")\n",
    "    return (np.array(X_roll).astype(np.float32),\n",
    "            np.array(X_stats).astype(np.float32),\n",
    "            to_categorical(np.array(y), num_classes=len(COMPOSERS)))\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 5: Split Dataset\n",
    "# ----------------------------------------\n",
    "def stratified_split_dataframe(df, label_col='composer', test_size=0.2, val_size=0.1, random_state=42):\n",
    "    label_map = {label: idx for idx, label in enumerate(sorted(df[label_col].unique()))}\n",
    "    y = df[label_col].map(label_map).values\n",
    "    sss1 = StratifiedShuffleSplit(n_splits=1, test_size=(test_size + val_size), random_state=random_state)\n",
    "    for train_idx, temp_idx in sss1.split(df, y):\n",
    "        train_df, temp_df = df.iloc[train_idx], df.iloc[temp_idx]\n",
    "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=test_size / (test_size + val_size), random_state=random_state)\n",
    "    y_temp = temp_df[label_col].map(label_map).values\n",
    "    for val_idx, test_idx in sss2.split(temp_df, y_temp):\n",
    "        val_df, test_df = temp_df.iloc[val_idx], temp_df.iloc[test_idx]\n",
    "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 6: Model Building (Hybrid CNN + MLP)\n",
    "# ----------------------------------------\n",
    "def build_hybrid_model(piano_roll_shape, stats_shape, num_classes):\n",
    "    roll_input = Input(shape=piano_roll_shape, name='roll_input')\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(roll_input)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    stats_input = Input(shape=(stats_shape,), name='stats_input')\n",
    "    s = layers.Dense(64, activation='relu')(stats_input)\n",
    "\n",
    "    merged = layers.concatenate([x, s])\n",
    "    merged = layers.Dense(128, activation='relu')(merged)\n",
    "    merged = layers.Dropout(0.4)(merged)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(merged)\n",
    "\n",
    "    model = Model(inputs=[roll_input, stats_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 7: Class Weights\n",
    "# ----------------------------------------\n",
    "def compute_class_weights(y_train_onehot):\n",
    "    y_int = np.argmax(y_train_onehot, axis=1)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_int), y=y_int)\n",
    "    return dict(enumerate(weights))\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 8: Training Wrapper\n",
    "# ----------------------------------------\n",
    "def train_hybrid_model(model, X_roll_train, X_stats_train, y_train, \n",
    "                       X_roll_val, X_stats_val, y_val, epochs=20, batch_size=32):\n",
    "    class_weights = compute_class_weights(y_train)\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(patience=3, factor=0.5)\n",
    "    ]\n",
    "    model.fit(\n",
    "        {'roll_input': X_roll_train, 'stats_input': X_stats_train},\n",
    "        y_train,\n",
    "        validation_data=({'roll_input': X_roll_val, 'stats_input': X_stats_val}, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. Load MIDI File Paths\n",
    "# ----------------------------------------\n",
    "df = get_midi_files(DATA_DIR, COMPOSERS)\n",
    "df = df[df['filepath'].apply(os.path.exists)]  # Just to be safe\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. Split into Train/Val/Test\n",
    "# ----------------------------------------\n",
    "train_df, val_df, test_df = stratified_split_dataframe(df)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3. Extract Features: Multichannel Piano Roll + Statistics\n",
    "# ----------------------------------------\n",
    "print(\"Extracting training data...\")\n",
    "X_train_roll, X_train_stats, y_train = create_combined_dataset(train_df)\n",
    "print(\"Extracting validation data...\")\n",
    "X_val_roll, X_val_stats, y_val = create_combined_dataset(val_df)\n",
    "print(\"Extracting test data...\")\n",
    "X_test_roll, X_test_stats, y_test = create_combined_dataset(test_df)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4. Build Hybrid Model\n",
    "# ----------------------------------------\n",
    "input_shape_roll = X_train_roll.shape[1:]    # (128, 150, 4)\n",
    "input_shape_stats = X_train_stats.shape[1]   # e.g., 10\n",
    "\n",
    "model = build_hybrid_model(input_shape_roll, input_shape_stats, num_classes=len(COMPOSERS))\n",
    "\n",
    "# ----------------------------------------\n",
    "# 5. Train the Model\n",
    "# ----------------------------------------\n",
    "trained_model = train_hybrid_model(model, \n",
    "                                   X_train_roll, X_train_stats, y_train,\n",
    "                                   X_val_roll, X_val_stats, y_val)\n",
    "\n",
    "# ----------------------------------------\n",
    "# 6. Evaluate the Model (optional)\n",
    "# ----------------------------------------\n",
    "test_loss, test_acc = trained_model.evaluate(\n",
    "    {'roll_input': X_test_roll, 'stats_input': X_test_stats}, y_test, verbose=0\n",
    ")\n",
    "print(f\"✅ Final Test Accuracy: {test_acc:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
